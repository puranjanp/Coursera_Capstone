{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to scrape the Wikipedia page <a href=https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M>List of postal codes of Canada: M</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install beautifulsoup4\n",
    "! pip install lxml\n",
    "! pip install geocoder\n",
    "# problem installing below 2 packages in local machine\n",
    "! pip install geopy\n",
    "! pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests\n",
    "! pip install html5lib\n",
    "! pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import requests\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the html of the page is just the first step. Next step is to create a Beautiful Soup object from the html. This is done by passing the html to the BeautifulSoup() function. The Beautiful Soup package is used to parse the html, that is, take the raw html text and break it into Python objects. The second argument 'lxml' is the html parser whose details you do not need to worry about at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To perform web scraping importing the libraries.\n",
    "The urllib.request module is used to open URLs.\n",
    "The Beautiful Soup package is used to extract data from html files.\n",
    "The Beautiful Soup library's name is bs4 which stands for Beautiful Soup version 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.title\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr = 'Toronto, Canada'\n",
    "geoloc = Nominatim(user_agent=\"toronto_explorer\")\n",
    "location = geoloc.geocode(addr)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())\n",
    "soup = soup.find_all('table', class_='wikitable sortable')\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "res = requests.get(\"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\")\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "table = soup.find_all('table')[0] \n",
    "df = pd.read_html(str(table))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "### Clean the data by filter out the Borough having value \"Not assigned\"\n",
    "df_data = df['Borough']!='Not assigned'\n",
    "df_main = df[df_data]\n",
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine multiple rows of Neighbourhood of same Borough\n",
    "df1 = df_main.groupby(['Postcode','Borough'])['Neighbourhood'].apply(', '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace Neighbourhoods having value \"Not assigned\" with value of Borough\n",
    "df1['Neighbourhood'] = np.where(df1['Neighbourhood']=='Not assigned', df1['Borough'], df1['Neighbourhood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import geodata from CSV file\n",
    "geodata = \"https://cocl.us/Geospatial_data/Geospatial_Coordinates.csv\"\n",
    "df_geodata = pd.read_csv(geodata)\n",
    "df_geodata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={\"Postcode\": \"Postal Code\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.set_index(['Postal Code'])\n",
    "df_geodata.set_index(['Postal Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now need to join both the dataframes on common key \"Postcode\"\n",
    "\n",
    "df_main = pd.merge(df1, df_geodata, on='Postal Code', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Let's explore neighborhoods in Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 100\n",
    "CLIENT_ID = 'HEUOIKGRIHN0N42H4SF0QD15XHFYVAJHQ3D2DHVZBRCUST0S'\n",
    "CLIENT_SECRET = 'ENEK5AYTY4XA4FCHBQQM5ZHFZNTRD1SCM5VPXGNHIMXDUBQN'\n",
    "VERSION = '20180604'\n",
    "# Create a new function\n",
    "def getVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    list_of_venues=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        list_of_venues.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    venues = pd.DataFrame([item for venue_list in list_of_venues for item in venue_list])\n",
    "    venues.columns = ['Neighbourhood', \n",
    "                  'Neighbourhood Latitude', \n",
    "                  'Neighbourhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_of_tornoto = getVenues(names=df_main['Neighbourhood'], \n",
    "                              latitudes=df_main['Latitude'],\n",
    "                              longitudes=df_main['Longitude']\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(venues_of_tornoto.shape)\n",
    "venues_of_tornoto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data = pd.get_dummies(venues_of_tornoto[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "# add neighbourhood column back to dataframe\n",
    "trans_data['Neighbourhood'] = venues_of_tornoto['Neighbourhood'] \n",
    "# move neighbourhood column to the first\n",
    "fixed_columns = [trans_data.columns[-1]] + list(trans_data.columns[:-1])\n",
    "trans_data = trans_data[fixed_columns]\n",
    "trans_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now group rows by neighbourhood taking mean of the frequency of occurrence of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_venue = trans_data.groupby('Neighbourhood').mean().reset_index()\n",
    "group_by_venue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's print each neighbourhood along with top 5 common venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topVenues = 5\n",
    "\n",
    "for v in group_by_venue['Neighbourhood']:\n",
    "    print(\"----\"+v+\"----\")\n",
    "    temp = group_by_venue[group_by_venue['Neighbourhood'] == v].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(topVenues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to sort the venues in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_venues(venue_var, top_how_many):\n",
    "    venue_cat = venue_var.iloc[1:]\n",
    "    sorted_venue_cat = venue_cat.sort_values(ascending=False)\n",
    "    \n",
    "    return sorted_venue_cat.index.values[0:top_how_many]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now create a new dataframe and display the top 10 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topVenues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "# create columns against top venues\n",
    "column_names = ['Neighbourhood']\n",
    "for ind in np.arange(topVenues):\n",
    "    try:\n",
    "        column_names.append('{}{} Most Frequent Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        column_names.append('{}th Most Frequent Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe of sorted venues\n",
    "sorted_v = pd.DataFrame(columns=column_names)\n",
    "sorted_v['Neighbourhood'] = group_by_venue['Neighbourhood']\n",
    "\n",
    "for ind in np.arange(group_by_venue.shape[0]):\n",
    "    sorted_v.iloc[ind, 1:] = common_venues(group_by_venue.iloc[ind, :], topVenues)\n",
    "\n",
    "sorted_v.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run k-means to cluster the neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of clusters to made\n",
    "no_c = 5\n",
    "\n",
    "venue_clusters = group_by_venue.drop('Neighbourhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=no_c, random_state=0).fit(venue_clusters)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cluster labels\n",
    "sorted_v.insert(0, 'Clusters', kmeans.labels_)\n",
    "\n",
    "tor_df = df_main\n",
    "\n",
    "# merge main dataframe with previous dataframe to add lat long for the neighbourhoods\n",
    "tor_df = tor_df.join(sorted_v.set_index('Neighbourhood'), on='Neighbourhood')\n",
    "tor_df = tor_df.fillna(0)\n",
    "tor_df[\"Clusters\"] = tor_df[\"Clusters\"].astype(int)\n",
    "tor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "cl_map = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(no_c)\n",
    "ys = [i + x + (i*x)**2 for i in range(no_c)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(tor_df['Latitude'], tor_df['Longitude'], tor_df['Neighbourhood'], tor_df['Clusters']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(cl_map)\n",
    "       \n",
    "cl_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
